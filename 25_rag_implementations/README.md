# ðŸš€ 25 RAG Implementation Project

A comprehensive implementation of 25 different Retrieval-Augmented Generation (RAG) systems using Local Ollama LLM.

## Quick Start (Windows)

1. **Setup Environment**:
   ```cmd
   cd 25_rag_implementations
   venv\Scripts\activate
   ```

2. **Install Ollama** (if not already installed):
   - Visit: https://ollama.ai/download
   - Download Windows installer

3. **Test Installation**:
   ```cmd
   python main.py test
   ```

4. **Run a Query**:
   ```cmd
   python main.py query standard --query "What is machine learning?"
   ```

## Project Structure

```
25_rag_implementations/
â”œâ”€â”€ common/                 # Shared components
â”‚   â”œâ”€â”€ models/            # Base models and interfaces
â”‚   â”œâ”€â”€ utils/             # Utility functions
â”‚   â””â”€â”€ config/            # Configuration management
â”œâ”€â”€ rag_types/             # Individual RAG implementations
â”‚   â”œâ”€â”€ 01_standard/       # Standard RAG
â”‚   â”œâ”€â”€ 02_conversational/ # Conversational RAG
â”‚   â””â”€â”€ ...               # 23 more RAG types
â”œâ”€â”€ data/                  # Test data and documents
â”œâ”€â”€ tests/                 # Test suites
â”œâ”€â”€ demos/                 # Demo applications
â””â”€â”€ logs/                  # Performance logs
```

## Available Commands

- `python main.py query <rag_type> --query "^<your_query^>"` - Process a query
- `python main.py test` - Run comprehensive tests

## Development Status

- âœ… Project structure created
- ðŸš§ RAG implementations in progress
- ðŸš§ Testing framework being built

## Next Steps

Follow the Technical Implementation Plan to build each RAG type systematically.
